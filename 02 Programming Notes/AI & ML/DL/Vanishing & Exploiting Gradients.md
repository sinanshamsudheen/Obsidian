
Vanishing - As number of hidden layers grow, gradient becomes very small and weights will hardly change. this will hamper the learning process.. its more prominent in deep Neural networks,
Solution: GRU, LSTM